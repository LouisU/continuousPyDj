# 异步和定时任务

## 异步任务
#### 创建一个users app. 创建users/tasks.py文件
```python
import time
from celery import  shared_task

@shared_task
def user_inform():
    print("send Sms to User")
    time.sleep(5)
    print("done")
```
#### users/views.py中
```python
from .tasks import user_inform

def do(request):
    # 执行异步任务
    print('start user request')
    user_inform.delay()
    print('end user request')
    return JsonResponse({'result': 'ok'})

```


#### urls.py文件中配置url ../do/
#### proj文件下运行： python manage.py runserver
#### proj文件下运行: celery -A continuousPyDj worker -l INFO
#### 访问url ../do/

```
# 访问url立刻返回
start user request
end user request
[05/May/2019 02:07:40] "GET /do/ HTTP/1.1" 200 16

# 而worker终端上，接到task,然后执行task,执行task消耗了5s
[2019-05-05 02:08:01,030: INFO/ForkPoolWorker-1] Task users.tasks.user_inform[50621697-5f1b-4336-98c6-5abfc1430d98] succeeded in 5.01094436s: None
[2019-05-05 02:08:13,664: INFO/MainProcess] Received task: users.tasks.user_inform[2d3ffb62-5113-4375-9274-5171d3975483]  
[2019-05-05 02:08:13,667: WARNING/ForkPoolWorker-3] send Sms to User
[2019-05-05 02:08:18,670: WARNING/ForkPoolWorker-3] done

可见, 访问API ../do后，接口立刻返回了。但异步任务仍然在后端执行。
```


## 定时任务
#### users/tasks.py文件中
```python
import time
from celery import  shared_task

@shared_task
def user_inform():
    print("send Sms to User")
    time.sleep(5)
    print("done")


@shared_task
def add(x, y):
    return x + y

@shared_task
def multiply(x, y):
    return x * y
```

#### proj/proj/celery.py文件中
```python
from celery.schedules import crontab

# 定义定时任务
app.conf.beat_schedule = {
    'task1': {
        'task': 'users.tasks.add',
        'schedule': 3.0,
        'args': (16, 16)
    },
    'task2': {
        'task': 'users.tasks.multiply',
        'schedule': crontab(minute='*/1'),
        'args': (16, 16)
    },

}
```

#### proj文件下运行: celery -A continuousPyDj beat -l INFO
#### proj文件下运行: celery -A continuousPyDj worker -l INFO
```shell
$ celery -A continuousPyDj beat -l INFO
celery beat v4.3.0 (rhubarb) is starting.
__    -    ... __   -        _
LocalTime -> 2019-05-05 02:05:45
Configuration ->
    . broker -> redis://localhost:6379/1
    . loader -> celery.loaders.app.AppLoader
    . scheduler -> celery.beat.PersistentScheduler
    . db -> celerybeat-schedule
    . logfile -> [stderr]@%INFO
    . maxinterval -> 5.00 minutes (300s)
[2019-05-05 02:05:45,552: INFO/MainProcess] beat: Starting...
[2019-05-05 02:05:45,571: INFO/MainProcess] Scheduler: Sending due task task2 (users.tasks.multiply)
[2019-05-05 02:05:45,593: INFO/MainProcess] Scheduler: Sending due task task1 (users.tasks.add)
[2019-05-05 02:05:48,593: INFO/MainProcess] Scheduler: Sending due task task1 (users.tasks.add)
[2019-05-05 02:05:51,593: INFO/MainProcess] Scheduler: Sending due task task1 (users.tasks.add)
[2019-05-05 02:05:54,593: INFO/MainProcess] Scheduler: Sending due task task1 (users.tasks.add)
[2019-05-05 02:05:57,593: INFO/MainProcess] Scheduler: Sending due task task1 (users.tasks.add)
[2019-05-05 02:06:00,000: INFO/MainProcess] Scheduler: Sending due task task2 (users.tasks.multiply)
[2019-05-05 02:06:00,593: INFO/MainProcess] Scheduler: Sending due task task1 (users.tasks.add)
[2019-05-05 02:06:03,593: INFO/MainProcess] Scheduler: Sending due task task1 (users.tasks.add)
....

$ celery -A continuousPyDj worker -l INFO
[2019-05-05 02:05:51,519: INFO/MainProcess] celery@wuhaodeMacBook-Pro.local ready.
[2019-05-05 02:05:51,796: INFO/MainProcess] Received task: users.tasks.add[cd28e577-c1cb-4833-b02b-4532058d045f]  
[2019-05-05 02:05:51,798: INFO/MainProcess] Received task: users.tasks.add[8be286ca-13db-4d73-ba58-a8e189634d92]  
[2019-05-05 02:05:51,802: INFO/MainProcess] Received task: users.tasks.add[6e076f3c-8e62-42e5-9fae-67469ead72d3]  
[2019-05-05 02:05:51,807: INFO/MainProcess] Received task: users.tasks.add[646d8202-c8f7-457f-8489-6a1c36bb6247]  
[2019-05-05 02:05:51,812: INFO/MainProcess] Received task: users.tasks.add[9bfe3e16-6e7d-42fc-bc09-43068f67b190]  
[2019-05-05 02:05:51,816: INFO/MainProcess] Received task: users.tasks.add[b02e814a-2c95-4b7b-88ff-2f759584a7be]  
[2019-05-05 02:05:51,816: INFO/ForkPoolWorker-1] Task users.tasks.add[8be286ca-13db-4d73-ba58-a8e189634d92] succeeded in 0.015334817000000278s: 32
[2019-05-05 02:05:51,818: INFO/MainProcess] Received task: users.tasks.add[cf900b3a-c923-46b5-8011-a2f761766971]  
[2019-05-05 02:05:51,818: INFO/ForkPoolWorker-8] Task users.tasks.add[cd28e577-c1cb-4833-b02b-4532058d045f] succeeded in 0.01644925999999991s: 32
[2019-05-05 02:05:51,820: INFO/MainProcess] Received task: users.tasks.add[d05c0773-05d6-423d-bc26-d4b9b55445d8]  
 ...
[2019-05-05 02:05:51,842: INFO/MainProcess] Received task: users.tasks.add[1f3e5211-8354-46ba-a21a-28a714aee823]  
[2019-05-05 02:05:51,844: INFO/ForkPoolWorker-3] Task users.tasks.add[1f3e5211-8354-46ba-a21a-28a714aee823] succeeded in 0.0007232299999997416s: 32
[2019-05-05 02:05:51,844: INFO/MainProcess] Received task: users.tasks.multiply[df263a33-2781-499a-8eb3-ce51bec9231b]  
[2019-05-05 02:05:51,847: INFO/MainProcess] Received task: users.tasks.add[03b19fc2-eef3-474b-9692-058cf8a2261c]  
[2019-05-05 02:05:51,850: INFO/ForkPoolWorker-5] Task users.tasks.multiply[df263a33-2781-499a-8eb3-ce51bec9231b] succeeded in 0.0024369459999999954s: 256
[2019-05-05 02:05:51,851: INFO/ForkPoolWorker-6] Task users.tasks.add[03b19fc2-eef3-474b-9692-058cf8a2261c] succeeded in 0.0026901549999998053s: 32
[2019-05-05 02:05:51,853: INFO/MainProcess] Received task: users.tasks.add[a6d30071-ae93-4821-8119-6ee078bb00c3]  
...
[2019-05-05 02:06:00,001: INFO/MainProcess] Received task: users.tasks.multiply[d2782b43-b156-49b9-bfed-1c55151ae540]  
[2019-05-05 02:06:00,003: INFO/ForkPoolWorker-8] Task users.tasks.multiply[d2782b43-b156-49b9-bfed-1c55151ae540] succeeded in 0.0006048899999999691s: 256
...



可见每三秒执行一次的users.tasks.add任务和每分钟执行一次的users.tasks.multiply任务都正常执行了。
```